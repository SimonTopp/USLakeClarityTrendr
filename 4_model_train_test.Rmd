---
title: "AquaModel Evalution"
author: "Simon Topp"
date: "3/01/2019"
output: html_document
editor_options:
  chunk_output_type: console
---
This script generates error metrics and figures for evaluating xgBoost model performance for AquaModel.  All error metrics are for testing data not used in model training.

```{r setup, include=FALSE}
library(tidyverse)
library(feather)
library(knitr)
library(purrr)
library(googledrive)
library(sf)
library(hydrolinks)
library(doParallel)
library(furrr)
library(lubridate)
library(xgboost)
library(onehot)
library(LAGOSNE)
library(Metrics)
library(viridis)
library(ggpmisc)
library(kableExtra)
library(groupdata2)
knitr::opts_chunk$set(error = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(echo = F)
```


## Now create all the models and the evaluation figures.

```{r}
## Bring in all the files needed in the script
# Landscape variables ranked by RF feature importance
rfeVars <- read_feather('out/RfeVariablesFull.feather')
#Check with old vars
#rfeVars <- read_feather('../aquaModel/out/dsweStrict2_100Full_rrFalse_RfeVariables.feather')  
#%>%
 # mutate(withinSD = gsub(pattern = 'elevation', replacement = 'ElevCat', x =withinSD))


## Evaluation sites pulled out of train/test data
sites.eval <- read_feather('out/evalSites.feather')

## Lagos/wqp for the associated lakes 
fieldObs <- read_feather('out/evalFieldObs.feather')

srMunged <- read_feather('out/srMunged.feather') %>%
    mutate(uniqueID = row_number(),
         siteParam = paste0(COMID, parameter)) %>%
  filter(!COMID %in% sites.eval$COMID) 


# Set the arguments
#dsweStrict_100FullWinSD
iteration = 'vSD2'
numAdd = -9999
cons <- c('secchi', 'tss', 'chl_a')
inputs <- rfeVars
log = 'ln'
filter <- T
weight <- F
ungroup <- T
area = 'eco'
e = environment()

if(area == 'eco'){
  region = st_read('in/NLA/NLA_Ecoregions/EcoRegsMerged.shp')
}else if(area == 'hucs'){
  region = st_read('in/hucs/hucs.shp') %>%
          mutate(HUC_2 = factor(as.numeric(HUC_2))) %>%
          group_by(HUC_2) %>%
          summarize(region = first(REGION))
}

source('0_ModellingFunctions.R')

#output <- read_feather(paste0('out/',iteration,'testOutput.feather'))
```


```{r, eval = T, include = F}
## Train the xgboost models

# Create training and testing data.
set.seed(461)
samples <- srMunged %>%
  group_by(parameter) %>%
  nest() %>%
  mutate(tt = purrr::map(data,traintest, ungroup = ungroup))

## Non-log models
set.seed(467)
results <- tibble(parameter = cons) %>% 
  mutate(boosts = purrr::map(parameter, ~boost(., samples,inputs, numAdd, filter = filter, weight = weight, log = 'none', save = T)),
         fit = purrr::map(boosts, 'eval.log'),
         results = purrr::map(boosts, 'results'))

## Log models
set.seed(51)
resultslog <- tibble(parameter = cons) %>% 
  mutate(boosts = purrr::map(parameter, ~boost(., samples,inputs, numAdd, filter = filter, weight = weight, log = 'ln', save = T)),
         fit = purrr::map(boosts, 'eval.log'),
         results = purrr::map(boosts, 'results'))

output <- results %>%
  select(results) %>%
  unnest() %>%
  bind_rows(resultslog %>% 
              select(results) %>%
              unnest()) 

evaluation <- results %>%
  select(fit) %>%
  unnest() %>%
  gather(train_rmse, test_rmse, key = 'Group', value = 'rmse') %>%
  bind_rows(resultslog %>%
              select(fit) %>%
              unnest() %>%
              gather(train_rmse, test_rmse, key = 'Group', value = 'rmse'))


write_feather(output, paste0('out/',iteration,'_Output.feather'))
```


```{r}
lakesDown <- list.files('out/EvalSites/qaPull', full.names = T)

#Extract vector of empty files' names
empties <- lakesDown[file.info(lakesDown)[["size"]]==1]
lakesDown <- lakesDown[!lakesDown %in% empties]

# Map over the pulled reflectance values and calculate time-series predictions for each constituent
ids <- unique(as.character(sites.eval$COMID))

ts.full <-  ids %>% purrr::map_dfr(~EvalPreds(.,lakesDown, sites.eval, 'secchi', log)) %>%
  bind_rows(ids %>% purrr::map_dfr(~EvalPreds(.,lakesDown, sites.eval, 'tss', log))) %>%
  bind_rows(ids %>% purrr::map_dfr(~EvalPreds(.,lakesDown, sites.eval, 'chl_a', log)))

```

### Model error metrics and landscape input variables.

##### Landscape variables included in model per parameter
```{r}
getVars <- function(i){
  if(numAdd == 0){
  features <- c('blue','green','red', 'nir','swir1', 'swir2', "NR", "BR", "GR",
    "SR", "BG", "BN", "BS", 'GS', 'GN', 'fai', 'ndvi', 'ndwi', 
    'sat', 'hillshade', 'zenith')
  }else if(numAdd > 0){
    features = rfeVars %>%
      filter(parameter == i) %>%
      select(var) %>%
      str_split(pattern = ', ') %>%
      first()
    #New method taking just the first 3 non-optical features from the RF RFE.
    features = c(features[!features %in% c('blue','green','red', 'nir','swir1',
                                           'swir2', "NR", "BR", "GR", "SR", "BG",
                                           "BN", "BS", 'GS', 'GN', 'fai', 'ndvi',
                                           'ndwi', 'sat', 'hillshade', 'zenith')][1:paste0(numAdd)],
                 'blue','green','red', 'nir','swir1', 'swir2', "NR", "BR", "GR",
                 "SR", "BG", "BN", "BS", 'GS', 'GN', 'fai', 'ndvi', 'ndwi',
                 'sat', 'hillshade', 'zenith')
  }else if(numAdd == -99){
    features = rfeVars %>%
    filter(parameter == i) %>%
    select(withinSD) %>%
    str_split(pattern = ', ') %>%
    first()
  #New method taking just the first 3 non-optical features from the RF RFE.
  features = c(features[!features %in% c('blue','green','red', 'nir','swir1',
                                           'swir2', "NR", "BR", "GR", "SR", "BG",
                                           "BN", "BS", 'GS', 'GN', 'fai', 'ndvi',
                                           'ndwi', 'sat', 'hillshade', 'zenith')],
                 'blue','green','red', 'nir','swir1', 'swir2', "NR", "BR", "GR",
                 "SR", "BG", "BN", "BS", 'GS', 'GN', 'fai', 'ndvi', 'ndwi',
                 'sat', 'hillshade', 'zenith')
  }else if(numAdd == -9999){
    features = rfeVars %>%
    filter(parameter == i) %>%
    select(withinSD2) %>%
    str_split(pattern = ', ') %>%
    first()
  #New method taking just the first 3 non-optical features from the RF RFE.
  features = c(features[!features %in% c('blue','green','red', 'nir','swir1',
                                           'swir2', "NR", "BR", "GR", "SR", "BG",
                                           "BN", "BS", 'GS', 'GN', 'fai', 'ndvi',
                                           'ndwi', 'sat', 'hillshade', 'zenith')],
                 'blue','green','red', 'nir','swir1', 'swir2', "NR", "BR", "GR",
                 "SR", "BG", "BN", "BS", 'GS', 'GN', 'fai', 'ndvi', 'ndwi',
                 'sat', 'hillshade', 'zenith')
  }
  out <- paste0(features, collapse = ', ')
  
  return(out)
} 

rfeVars %>%
  mutate(landsScapeVars = purrr:::map(rfeVars$parameter, getVars)) %>%
  select(parameter, landsScapeVars) %>%
  kable() %>% kable_styling %>% scroll_box(width = '4in', height = '3in')

```

##### Model error metrics (based on test data)

```{r}
#output <- read_feather('out/StrictSecchiSD_UnWeightedtestOutput.feather')
#iteration = "StrictSecchiSD_UnWeighted"
evals <- output %>%
  group_by(Param, log) %>%
  summarise(rmse = rmse(Actual, Predicted),
            mae = mae(Actual, Predicted),
            mape = mape(Actual, Predicted),
            bias = bias(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            smape = smape(Actual, Predicted)) %>%
  mutate(iteration = iteration)

evals %>% kable(digits = 2) %>% kable_styling() %>% scroll_box(width = '4in')

ggplot(output %>% filter(log == e$log), aes(x = Actual, y = Predicted)) + 
  geom_hex(aes(fill = ..count..)) + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  scale_x_continuous(trans = 'log10', labels = scales::comma) +
  scale_y_continuous(trans = 'log10', labels = scales::comma) +
  #coord_equal(ratio = 1) +
  facet_wrap(~Param, scales = 'free', shrink = T) +
  labs(title = 'XgBoost Water Quality Models', subtitle = 'Red line is 1:1')

output.full <- output %>%
  #filter(log == 'ln') %>%
  left_join(srMunged, by = c('uniqueID')) %>%
  mutate(residual = Actual - Predicted,
         year = year(date),
         month = month(date))

## Some weird hacks for reordering factors
reorder_within <- function(x, by, within, fun = mean, sep = "___", ...) {
  new_x <- paste(x, within, sep = sep)
  stats::reorder(new_x, by, FUN = fun)
}

scale_x_reordered <- function(..., sep = "___") {
  reg <- paste0(sep, ".+$")
  ggplot2::scale_x_discrete(labels = function(x) gsub(reg, "", x), ...)
}
# 
# ## Summary Error metrics
# ## By actual value quantile
# errorSum <- output.full %>%
#   group_by(Param, log) %>%
#   mutate(quantile = cut_number(Actual, 10, right = F, labels = F),
#          quantLabs = cut_number(Actual, 10,  right = F, dig.lab = 1)) %>%
#   ungroup() %>%
#   group_by(Param, log, quantile, quantLabs) %>%
#   summarize(rmse = rmse(Actual, Predicted),
#             #mae = mae(Actual, Predicted),
#             bias = bias(Actual, Predicted))%>%
#   gather(rmse:bias, key = 'Metric', value = 'Value') %>%
#   arrange(Param, log, Metric, quantile) %>%
#   as.data.frame() %>%
#   mutate(order = row_number())
# 
# ggplot(errorSum, aes(x = reorder_within(quantLabs, quantile, Param), y = Value, color = Metric, linetype = log, group = interaction(Metric, Param, log))) +
#   geom_point() +
#   geom_line() +
#   scale_x_reordered() +
#   facet_wrap(~Param, scales = 'free') +
#   theme_bw() +
#   theme(axis.text.x = element_text(angle = 90, vjust = .5)) +
#   labs(title = 'Error by In Situ Value binned into 10% Quantiles') +
#   xlab('Binned Field Obs')


## Summary metrics across space time and observed value
errorSum <- output.full %>%
  #filter(Param == 'secchi') %>%
  mutate(Observed.Value = Actual) %>%
  rename(Year = year, Latitude = lat, Longitude = long) %>%
  gather(Observed.Value, Year, Latitude, Longitude, key = 'Variable', value = 'Value') %>%
  group_by(Variable, Param, log) %>%
  mutate(quantile = cut_number(Value, 10, right = F, labels = F),
         quantLabs = cut_number(Value, 10,  right = F, dig.lab = 1)) %>%
  ungroup() %>%
  group_by(quantile, quantLabs, Param, Variable, log) %>%
  summarize(mae = mae(Actual, Predicted),
            smape = smape(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            #mae = mae(Actual, Predicted),
            bias = bias(Actual, Predicted)) %>%
  gather(mae:bias, key = 'Metric', value = 'Error') %>%
  as.data.frame() %>%
  arrange(Param, Variable, quantile) %>%
  mutate(order = row_number())


spaceTimeFigs('secchi')
spaceTimeFigs('secchi', abs = F)
spaceTimeFigs('chl_a')
spaceTimeFigs('chl_a', abs = F)
spaceTimeFigs('tss')
spaceTimeFigs('tss', abs = F)

ggplot(evaluation %>% filter(log == e$log), aes(x = iter, y = rmse, color = Group)) + 
  geom_line() +
  facet_wrap(~Param, scales = 'free') +  
  theme_bw() +
  labs(title = 'Model Evaluation Log') + 
       xlab('Iteration')

f.imp <- list.files('out/featureImp', full.names = T) %>%
  grep(pattern = iteration, value = T) %>%
  map_df(.,read_feather) %>%
  filter(log == e$log) %>%
  mutate(Feature = factor(Feature),
         Ordering = -as.numeric(factor(Parameter)) + Gain,
         Feature = fct_reorder(Feature, Ordering, .desc = T),
         r = row_number())

```



```{r, fig.height= 8}
output.full <- output.full %>%
  filter(Param == 'secchi', log == e$log) %>%
  st_as_sf(coords = c('long','lat'), crs = 4326) %>% 
  st_join(region %>% st_transform(.,4326)) 

output.full %>% 
  group_by(sat) %>%
  summarize(mae = mae(Actual, Predicted),
            smape = smape(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            #mae = mae(Actual, Predicted),
            bias = bias(Actual, Predicted)) %>%
  gather(mae:bias, key = 'Metric', value = 'Error') %>%
  ggplot(., aes(x = Metric, y = Error, fill = sat)) +
  geom_col(position = 'dodge') +
  theme_bw() + 
  ggtitle('Absolute and Relative Error by Satellite')
  
val.conf <- output.full %>%
  mutate(smape = 2*(abs(Actual - Predicted)/(abs(Actual) + abs(Predicted))),
         p.bias = (Actual - Predicted)/abs(Actual)) %>%
  group_by(region, sat, log) %>%
  summarize(smape = sd(smape),
            p.bias = sd(p.bias)) %>%
  mutate(p.bias = ifelse(is.na(p.bias), 0, p.bias),
         smape = ifelse(is.na(smape), 0, smape)) %>%
  gather(smape, p.bias, key = 'Metric', value = 'sd') %>%
  st_set_geometry(NULL)
  
output.full %>%
  group_by(region, sat, log) %>%
  summarize(smape = smape(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            count = n()) %>%
  gather(smape:p.bias, key = 'Metric', value = 'value') %>%
  left_join(val.conf %>% select(region, sat, Metric, sd)) %>%
  ggplot(.) +
  scale_fill_viridis_c(trans = 'log10') +
  #geom_text(x = .5, y = .5) +
  geom_col(position = 'dodge', aes(x = Metric, y = value, fill = count, color = sat, group = sat)) +
  geom_errorbar(position = position_dodge(.9), aes(x = Metric, ymin = value - sd, ymax = value + sd, group = sat), width = .2) +
  #scale_y_continuous(labels = scales::percent) +
  theme(legend.position = 'top') +
  ggtitle('Error by region') +
  facet_wrap(~region, scales = 'free')#, ncol = 4)

ggplot(output.full %>% filter(log == e$log), aes(x = Actual, y = Predicted)) + 
  geom_point(alpha = .3) +
  geom_smooth(method = 'lm', aes(color = sat)) +
  #scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  #geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  scale_x_continuous(trans = 'log10', labels = scales::comma) +
  scale_y_continuous(trans = 'log10', labels = scales::comma) +
  #coord_equal(ratio = 1) +
  facet_wrap(~region, scales = 'free', shrink = T) +
  labs(title = 'Regional Evaluation Performance')

dummy <- expand.grid(year = seq(1984,2018), month = c(1:12), region = factor(unique(region$region)))

fieldmatch <- output.full %>%
  filter(year < 2019,
         !is.na(region)) %>%
  rename(RS = Predicted, Field = Actual) %>%
  gather(RS,Field, key = 'Measure', value = 'value') %>%
  group_by(year, Measure, month, region) %>%
  summarise(median = median(value, na.rm = T),
            sd = sd(value, na.rm =T),
            count.obs = n())%>%
  right_join(dummy)%>%
  arrange(region,year, month)%>%
  mutate(date = as.POSIXct(paste0(year,'/',month,'/',01)))

ggplot(fieldmatch %>% na.omit(), aes(date, y = median, color = Measure)) + 
  geom_point(alpha = .1) +
  geom_smooth(method = 'loess', span = .2, se = F) + 
  facet_wrap(~region, scales = 'free', ncol = 4) +
  labs(title = 'Smoothed SDD Trends By Region Using Coincident Testing Data') +
  theme_bw() +
  theme(legend.position = 'bottom')

```


```{r, fig.height= 8}
ggplot(f.imp, aes(x = as.factor(r), y = Gain)) + 
  geom_col() +
  labs(x = 'Variables', title = "Feature Importance") +
  coord_flip() +
  facet_wrap(~Parameter, scales = 'free') +
  scale_x_discrete(breaks = f.imp$r, labels = f.imp$Feature)

```

### Visual Evalution of ~10 randomly selected lakes

These lakes were removed from train/test data.  The in situ vs satellite data are +/-1 month matchups.  Also, field measurements are coming from a single point whereas RS predictions are based on median reflectance values for the entire lake.

```{r, fig.height = 8}
## Big plots
##Read in the data to look
#ts.full <- read_feather('out/macroSystems/dsweStrictUnGroupedOptvarWeighted_MSxgboostPreds.feather')
## Take a quick look.
ts.full <- ts.full %>%
  mutate(source = 'RS',
         date = as_date(ymd_hms(date)),
         week = week(date)) %>%
  select(date, year, week, source, value, parameter, COMID) 


fieldObs <- fieldObs %>% 
  #filter(parameter == 'secchi') %>%
  mutate(date = as_date(ymd_hms(date_unity)),
  year = year(date),
  week = week(date),
  source = 'inSitu') %>%
  select(date, year, week, source, value, parameter, COMID) %>%
  filter(year > 1984,
         !(value > 20 & parameter == 'secchi'))

lagosRS.join <- ts.full %>%
  bind_rows(fieldObs %>% group_by(date, parameter, COMID, source, week, year) %>%
              summarize(value = mean(value))) %>%
  mutate(siteParam = paste0(parameter,'_', COMID),
         myID = paste0(year(date),month(date), COMID, parameter))

fieldObsdates <- lagosRS.join %>% filter(source == 'inSitu') %>% select(myID)

ts.out <- lagosRS.join %>% filter(myID %in% fieldObsdates$myID)

ggplot(ts.out) + geom_point(aes(x = date, y = value, color = source, shape = parameter), alpha = .7) +
  geom_smooth(aes(x = date, y = value, linetype = source), method = 'loess', se = F) +
  #scale_color_viridis_d() +
facet_wrap(~siteParam, scales = 'free', ncol = 4) + 
  theme(strip.background = element_blank(), strip.text.x = element_blank(), legend.position = 'top') +
  labs(title = 'Field vs Predicted Observations Over Time')


ggplot(ts.out) + geom_density(aes(x = value, fill = source, color = parameter), alpha = .5, size = .7) +
  scale_color_viridis_d() +
  facet_wrap(~siteParam, scales = 'free', ncol = 4) + 
  theme(
  strip.background = element_blank(),
  strip.text.x = element_blank(),
  legend.position = 'top') +
  labs(title = 'Field vs Predicted Observations Distributions')
```


```{r, eval = F}
ts.match <- ts.full %>%
  inner_join(fieldObs, by = c('year', 'week', 'COMID', 'parameter')) %>%
  rename(date.rs = date.x, date.is = date.y, value.rs = value.x, value.is = value.y) %>%
  mutate(date.diff = as.numeric(date.rs - date.is),
         siteParam = paste0(parameter,'_', COMID)) %>%
  filter(abs(date.diff) < 5)

ggplot(ts.match, aes(x = value.is, y = value.rs)) + 
  geom_point(aes(color = COMID)) + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  scale_x_log10() +
  scale_y_log10() +
   theme(
   legend.position = 'none') +
  facet_wrap(~parameter, scales = 'free', shrink = T) +
  labs(title = 'Evaluation Match-Up Data', subtitle = 'Red line is 1:1')


check <- fieldObs %>%
  group_by(date, parameter, COMID) %>%
  summarize(count = n(),
            mean = mean(value),
            sd = sd(value)) %>%
  na.omit()

ggplot(check, aes(x = mean, y = sd)) + geom_point(aes(color = parameter)) + xlim(0,10) + ylim(0,5) + labs(title = 'Mean and St.Dev of Same-Day in-situ observations')
```
