---
title: "3_ModelCalVal"
author: "Simon Topp"
date: "8/27/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---
# This script evaluates our model using the hold-out data in a variety of different ways.

```{r Eval}
#Get general evaluation metrics
evals <- output %>%
  summarise(rmse = rmse(Actual, Predicted),
            mae = mae(Actual, Predicted),
            mape = mape(Actual, Predicted),
            bias = bias(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            smape = smape(Actual, Predicted)) %>%
  mutate(iteration = iteration)

evals %>% kable(digits = 5) %>% kable_styling() %>% scroll_box(width = '4in')

ggplot(output, aes(x = Actual, y = Predicted)) + 
  geom_hex(aes(fill = ..count..)) + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  #scale_x_continuous(trans = 'log10', labels = scales::comma) +
  #scale_y_continuous(trans = 'log10', labels = scales::comma) +
  #coord_equal(ratio = 1) +
  labs(title = 'Full Validation', subtitle = 'Red line is 1:1', x = 'Actual', y = 'Predicted')

ggsave('figures/ModelValidation.png', width = 4, height = 3.5, units = 'in')

# We overpredict low values and underpredict high ones, see how badly we do this
output %>% mutate(groups = cut_number(Actual, 10, labels = F)) %>% group_by(groups) %>% summarise(bias = bias(Actual, Predicted)) %>% ggplot(aes(x = groups, y = bias)) + geom_point() + theme_bw() + labs(title = 'Bias over value range', x  = 'deciles', y = 'Bias')

ggsave('figures/BiasOverValues.png', width = 3, height = 2.5, units = 'in')

#Join back up the full dataframe to examine error accross observation attributes
output.full <- output %>%
  left_join(srMunged, by = 'UniqueID') %>%
  mutate(residual = Actual - Predicted,
         year = year(date),
         month = month(date))

## Quick look at validation metrics from 91-93
evals_9193 <- output.full %>% filter(year %in% c(1991, 1992,1993)) %>%
  summarise(rmse = rmse(Actual, Predicted),
            mae = mae(Actual, Predicted),
            mape = mape(Actual, Predicted),
            bias = bias(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            smape = smape(Actual, Predicted))

evals_9193
evals

tableGrob(evals_9193 %>% 
             select(mae, mape, bias) %>% 
             mutate_all(round, 3), rows = NULL)

tableGrob(evals %>% 
             select(mae, mape, bias) %>% 
             mutate_all(round, 3), rows = NULL)

ggplot(output.full %>% filter(year %in% c(1991, 1992,1993)), aes(x = Actual, y = Predicted)) + 
  geom_hex(aes(fill = ..count..)) + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  #scale_x_continuous(trans = 'log10', labels = scales::comma) +
  #scale_y_continuous(trans = 'log10', labels = scales::comma) +
  #coord_equal(ratio = 1) +
  labs(title = '1991-1993 Validation', subtitle = 'Red line is 1:1', x = 'Actual', y = 'Predicted')


# g <- grid.arrange(p3,p1,p4,p2, nrow = 2, heights = c(1,.3))
# ggsave('figures/val_fullV9193.png', plot = g, width = 6.5, height = 4, units = 'in', dpi = 600)

## Secondary Validation figure
## Look at validation by lake size
p1 <- output.full %>% mutate(Size.Group = cut(areasqkm, breaks = c(-1,.1,1,10,100,100000), labels = c('<.1','.1-1','1-10', '10-100', '>100'))) %>% ggplot(aes(x = Actual, y = Predicted)) + 
  geom_hex(aes(fill = ..count..)) + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.1, size = 3) +
  #coord_fixed() +
  theme_bw() +
  theme(aspect.ratio = 1) +
  labs(title = 'Hold-Out Validation by: Lake Size (sq. km)', x = 'Actual', y = 'Predicted', tag = 'A)') +
  facet_wrap(~Size.Group)

## Validation by satellite
p2 <- output.full %>% 
  mutate(sat = factor(sat, levels = c('l5', 'l7','l8'), labels = c('Landsat 5', 'Landsat 7', 'Landsat 8'))) %>%
  ggplot(aes(x = Actual, y = Predicted)) + 
  geom_hex(aes(fill = ..count..)) + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.1, size = 3) +
  labs(title = 'Sensor', x = 'Actual', y = 'Predicted', tag = 'B)') +
  #coord_fixed() +
  theme_bw() +
  theme(aspect.ratio = 1) +
  facet_wrap(~sat, nrow = 1)

## Look at Error between LAGOS and WQP obs per reviewer request.
p3 <- output.full %>% 
  ggplot(aes(x = Actual, y = Predicted)) + 
  geom_hex(aes(fill = ..count..)) + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.1, size = 3) +
  labs(title = 'Data Source', x = 'Actual', y = 'Predicted', tag = 'C)') +
  #coord_fixed() +
  theme_bw() +
  theme(aspect.ratio = 1) +
  facet_wrap(~source, nrow = 1)


## By year
p4 <- output.full %>% group_by(year) %>% summarise(bias = bias(Actual, Predicted)) %>%
  ggplot(aes(x = year, y = bias)) + 
  geom_point() + geom_line() + 
  geom_smooth(method = 'lm') +
  theme_bw() + 
  labs(title = 'Hold-Out Bias by Year', tag = 'D)', x = 'Year', y = 'Bias (Actual-Predicted)') +
  ggpubr::stat_regline_equation(label.x.npc = 'middle', label.y.npc  = 'top')

layout <- rbind(c(1,1,1,1), c(1,1,1,1),c(1,1,1,1),c(2,2,2,2),c(2,2,2,2),c(3,3,3,NA), c(3,3,3,NA),c(4,4,4,NA), c(4,4,4,NA))
g <- grid.arrange(p1,p2,p3,p4, layout_matrix = layout, respect = T)
ggpubr::ggarrange(p1,p2,p3,p4, nrow = 4)
cowplot::plot_grid(p1, p2,p3,p4, nrow = 4, rel)
ggsave('figures/ValidationBreakDown.png', width = 7, height = 9, units = 'in', plot = g)


  
##look for errors associated with certain things
output.full %>% ggplot(., aes(x = residual, y = AOD)) + geom_hex()

## Some weird hacks for reordering factors
reorder_within <- function(x, by, within, fun = mean, sep = "___", ...) {
  new_x <- paste(x, within, sep = sep)
  stats::reorder(new_x, by, FUN = fun)
}

scale_x_reordered <- function(..., sep = "___") {
  reg <- paste0(sep, ".+$")
  ggplot2::scale_x_discrete(labels = function(x) gsub(reg, "", x), ...)
}

## Summary metrics across space, time, and observed value
errorSum <- output.full %>%
  #filter(Param == 'secchi') %>%
  mutate(Observed.Value = Actual) %>%
  rename(Year = year, Latitude = lat, Longitude = long) %>%
  gather(Observed.Value, Year, Latitude, Longitude, key = 'Variable', value = 'Value') %>%
  group_by(Variable, log) %>%
  mutate(quantile = cut_number(Value, 10, right = F, labels = F),
         quantLabs = cut_number(Value, 10,  right = F, dig.lab = 1)) %>%
  ungroup() %>%
  group_by(quantile, quantLabs, Variable, log) %>%
  dplyr::summarise(mae = mae(Actual, Predicted),
            smape = smape(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            #mae = mae(Actual, Predicted),
            bias = bias(Actual, Predicted)) %>%
  gather(mae:bias, key = 'Metric', value = 'Error') %>%
  as.data.frame() %>%
  arrange(Variable, quantile) %>%
  mutate(order = row_number())

spaceTimeFigs()
ggsave('figures/SpaceTimeAbs.png', width = 4, height = 5, units = 'in')
spaceTimeFigs(abs = F)
ggsave('figures/SpaceTimeRel.png', width = 4, height = 5, units = 'in')

##  Look at distribution of residuals across time
output.full %>% mutate(yearGroups = cut_number(year, 20)) %>%
  ggplot(., aes(x = yearGroups, y = residual)) + 
  #geom_boxplot() +
  geom_violin(draw_quantiles = c(.25,.5,.75)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = .5))

##View the feature importance
model$modelInfo$varImp(model$finalModel) %>%
  mutate(Feature = fct_reorder(rownames(.), Overall, .desc = T)) %>%
  arrange(Overall) %>%
  ggplot(., aes(x = Feature, y = Overall)) + 
  geom_col() +
  #scale_x_discrete(labels = c('Forel-Ule Index','Mean Temperature','Lake Depth', 'Wetland Cover','Mean Runoff', 'Forest Cover','Topographic Wetness', 'Water Table Depth', 'Blue/Green','NIR/Red','Kffactor (Erosion Index)')) +  #For final make labels nice
  coord_flip() +
  theme_bw() +
  labs(title = 'Feature Importance', y = 'Importance (Model Gain)') 

ggsave('figures/FeatImp.png', width = 3.5, height = 3, units = 'in')
```

## Generate ALE values to examine predictor influences on the model

```{r}
library(iml)
## Filter to training data and plug it all into the interpretable machine learning environment
data <- srMunged %>% filter(!UniqueID %in% output$UniqueID) %>%  dplyr::select(all_of(features),value) %>% na.omit()
predictor <- Predictor$new(model, data = data %>% dplyr::select(-value), y = data$value)

#Generate ALE values
effs <- FeatureEffects$new(predictor)
effs.df <- do.call('rbind', effs$results)

# Rename with human readable names
name.changer <- tibble(.feature = features, names.New = c('Dominant Wavelength (FUI)','Mean Temperature', 'Blue/Green', 'Lake Depth', 'NIR/Red', 'Wetland Cover','Mean Runoff', 'Forest Cover','Water Table Depth', 'Kffactor (Erosion Index)', 'Topographic Wetness'))

effs.df <- effs.df %>% left_join(name.changer)

write_feather(effs.df, 'out/gbLinera_ALE.feather')
effs.df <- read_feather('out/gbLinera_ALE.feather')


alePlotter <- function(feature){
  #ALE values shouldn't be extrapolated over limited observations, so remove the ends of our distributions.
  perc5 = quantile(data[[feature]],.05)
  perc95 = quantile(data[[feature]],0.95)
  
  
  ## Plot data distribution
  p1 <- ggplot(data, aes_string(x = feature)) + geom_density(adjust = 4, fill = 'grey70') +
    xlim(perc5,perc95) + 
    theme_classic() +
    theme(axis.text = element_text(color = 'transparent'),
          axis.title = element_blank(),
          #axis.title.y = element_text(color = 'transparent'),
          axis.ticks = element_blank(),
          axis.line = element_line(color = 'transparent'),
          plot.margin = margin(0,0,-1,0))
  
  ## Plot ALE values
  p2 <- effs.df %>% filter(.feature == feature, .borders >= perc5, .borders <= perc95) %>%
    ggplot(.,aes(x= .borders, y = .value)) +
    geom_line() +
    xlim(perc5,perc95) +
    ylim(-1.1,1) +
    facet_wrap(~names.New) +
    theme_bw() +
    theme(axis.title = element_blank(),
          plot.margin = margin(-3,0,0,0))
  
  grid.arrange(p1,p2, nrow = 2, heights = c(.25,1))
  }


p1 <- alePlotter(features[1])  
p2 <- alePlotter(features[2])
p3 <- alePlotter(features[3])
p4 <- alePlotter(features[4])
p5 <- alePlotter(features[5])
p6 <- alePlotter(features[6])
p7 <- alePlotter(features[7])
p8 <- alePlotter(features[8])
p9 <- alePlotter(features[9])
p10 <- alePlotter(features[10])
p11 <- alePlotter(features[11])


#Add feature importance plot for manuscript fig.
p12 <- model$modelInfo$varImp(model$finalModel) %>%
  mutate(Feature = fct_reorder(rownames(.), Overall, .desc = T)) %>%
  arrange(Overall) %>%
  ggplot(., aes(x = Feature, y = Overall)) + 
  geom_col() +
  scale_x_discrete(labels = c('Dom. Wavelength','Mean Temp','Lake Depth', 'Wetland Cover','Mean Runoff', 'Forest Cover','TPI', 'Water Table Depth', 'Blue/Green','NIR/Red','Erosion Index')) +  #For final make labels nice
  theme_bw() +
  labs(y = 'Importance') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        axis.title.x = element_blank())

g <- grid.arrange(p12, p1,p3,p5, p2,p4, p6,p7,p8,p11, p9,p10, nrow = 4, left = 'Accumulated Local Effect', bottom = 'Feature Value')


ggsave('figures/ImpAle.png', plot = g, width = 6.5, height = 7, units = 'in', dpi = 600)
```



# Regional/Satellite specific model fit.

```{r, fig.height= 8}
#Figure for error by satellite
output.full %>% 
  group_by(sat) %>%
  summarise(mae = mae(Actual, Predicted),
            smape = smape(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            #mae = mae(Actual, Predicted),
            bias = bias(Actual, Predicted)) %>%
  gather(mae:bias, key = 'Metric', value = 'Error') %>%
  ggplot(., aes(x = Metric, y = Error, fill = sat)) +
  geom_col(position = 'dodge') +
  theme_bw() + 
  ggtitle('Absolute and Relative Error by Satellite')

ggsave('figures/ErrorBySat.png', width = 3, height = 2.5)  

#Generate confidence intervals for erros metrics
val.conf <- output.full %>%
  mutate(smape = 2*(abs(Actual - Predicted)/(abs(Actual) + abs(Predicted))),
         p.bias = (Actual - Predicted)/abs(Actual)) %>%
  group_by(region, sat, log) %>%
  summarise(smape = sd(smape),
            p.bias = sd(p.bias)) %>%
  mutate(p.bias = ifelse(is.na(p.bias), 0, p.bias),
         smape = ifelse(is.na(smape), 0, smape)) %>%
  gather(smape, p.bias, key = 'Metric', value = 'sd')

#regional breakdown by satellite  
output.full %>%
  group_by(region, sat, log) %>%
  summarise(smape = smape(Actual, Predicted),
            p.bias = percent_bias(Actual, Predicted),
            count = n()) %>%
  gather(smape:p.bias, key = 'Metric', value = 'value') %>%
  left_join(val.conf %>% select(region, sat, Metric, sd)) %>%
  ggplot(.) +
  scale_fill_viridis_c(trans = 'log10') +
  #geom_text(x = .5, y = .5) +
  geom_col(position = 'dodge', aes(x = Metric, y = value, fill = count, color = sat, group = sat)) +
  geom_errorbar(position = position_dodge(.9), aes(x = Metric, ymin = value - sd, ymax = value + sd, group = sat), width = .2) +
  #scale_y_continuous(labels = scales::percent) +
  theme(legend.position = 'top') +
  ggtitle('Error by region') +
  facet_wrap(~region, scales = 'free')#, ncol = 4)

ggsave('figures/RegionalErrors.png', width =6, height = 6, units = 'in')

ggplot(output.full, aes(x = residual, color = sat)) + geom_density() + facet_wrap(~region)

#Model fit by satellite
ggplot(output.full, aes(x = Actual, y = Predicted)) + 
  geom_point(alpha = .3) +
  geom_smooth(method = 'lm', aes(color = sat)) +
  #scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  #geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  #scale_x_continuous(trans = 'log10', labels = scales::comma) +
  #scale_y_continuous(trans = 'log10', labels = scales::comma) +
  #coord_equal(ratio = 1) +
  facet_wrap(~region, scales = 'free', shrink = T) +
  labs(title = 'Regional Evaluation Performance') + theme_bw()

ggsave('figures/RegionalModelFit.png', width = 6.5, height =6, units = 'in')

dummy <- expand.grid(year = seq(1985,2018), month = c(1:12), region = factor(unique(region$region)))

## Replicate the regional/annual aggregation in the analysis to get aggregated error metrics
fieldmatch.coin <- output.full %>%
  filter(year < 2019,
         month %in% c(5:9)) %>%
  rename(Modelled = Predicted, In.Situ = Actual) %>%
  gather(Modelled, In.Situ, key = 'Measure', value = 'value') %>%
  group_by(year, COMID, Measure, region) %>%
  summarise(value = median(value)) %>%
  group_by(year, Measure, region) %>%
  summarise(mean = mean(value))

p1 <- ggplot(output, aes(x = Actual, y = Predicted)) + 
  geom_hex(aes(fill = ..count..)) + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  #scale_x_continuous(trans = 'log10', labels = scales::comma) +
  #scale_y_continuous(trans = 'log10', labels = scales::comma) +
  #coord_equal(ratio = 1) +
  labs(title = 'Observation Level Validation', x = 'In Situ (m)', y = 'Remote Sensing (m)')

p2 <- fieldmatch.coin %>%
  spread(Measure, mean) %>%
  ggplot(.,aes(x = In.Situ, y = Modelled)) + 
  #geom_hex(aes(fill = ..count..)) + 
  geom_point() + 
  scale_fill_viridis(name = 'Point\nCount', trans = 'log10') + 
  geom_abline(color = 'red') + 
  stat_poly_eq(aes(label =  paste(stat(adj.rr.label))),
               formula = y~x, parse = TRUE, 
               label.y = Inf, vjust = 1.3) +
  #scale_x_continuous(trans = 'log10', labels = scales::comma) +
  #scale_y_continuous(trans = 'log10', labels = scales::comma) +
  #coord_equal(ratio = 1) +
  labs(title = 'Aggregated Validation', x = 'In Situ (m)', y = 'Remote Sensing (m)')


p3 <- ggplot(fieldmatch.coin, aes(x = year, y = mean, color = Measure)) + 
  #geom_point(alpha = .1) +
  geom_line() + 
  scale_color_viridis_d(end = .6, labels = c('In Situ', 'Remote Sensing')) +
  facet_wrap(~region, scales = 'free', ncol = 2) +
  labs(title = 'Timeseries Using Coincident Hold-Out Data',
       x = 'Year', y = 'Mean Summer Clarity (m)') +
  theme_bw() +
  theme(legend.position = c(.75,.1),
        legend.direction = 'horizontal')


layout <- rbind(c(1,2),c(3,3),c(3,3))
g <- grid.arrange(p1,p2, p3, layout_matrix = layout)

#Figure 1: Validation
ggsave('figures/HoldOutValidation.png', plot = g, width = 6.5, height = 8, units = 'in')

evals.aggregated <- fieldmatch.coin %>%
  spread(Measure, mean) %>%
  ungroup() %>%
  summarise(rmse = rmse(In.Situ, Modelled),
            mae = mae(In.Situ, Modelled),
            mape = mape(In.Situ, Modelled),
            bias = bias(In.Situ, Modelled),
            p.bias = percent_bias(In.Situ, Modelled),
            smape = smape(In.Situ, Modelled)) %>%
  mutate(iteration = iteration)

evals.aggregated %>% kable(digits = 2) %>% kable_styling() %>% scroll_box(width = '4in')

evals %>% select(mae, mape, bias) %>% mutate(Validation = 'Point.Based') %>% bind_rows(evals.aggregated %>% select(mae, mape, bias) %>% mutate(Validation = 'Aggregated')) %>%
  mutate_if(is.numeric, round, 3) %>%
  kable() %>%
  kable_styling()

## Next do it with all the field data we got.  
# We add the additional step of averaging per lake before per month because sampling is really uneven. 
# Load in lagos and wqp data
# sites <- read_feather('../Aquasat/2_rsdata/out/unique_site_inventory.feather')
# 
# wqp.lagos <- read_feather('../Aquasat/1_wqdata/out/wqp_lagos_unity.feather') %>%
#   dplyr::select(SiteID, date_unity, source, value = secchi) %>%
#   na.omit() %>%
#   filter(value > 0.01, 
#          value < 15) %>%
#   left_join(sites) %>%
#   filter(!is.na(lat)) %>%
#   mutate(year = year(date_unity),
#          month = month(date_unity)) %>%
#   filter(month %in% c(5:9),
#          year > 1983, year < 2019) %>%
#   group_by(year, SiteID, lat, long) %>%
#   dplyr::summarize(median = median(value),
#                    count = n())
# 
# plan(multiprocess)
# site.join <- wqp.lagos %>%
#   ungroup() %>%
#   distinct(SiteID, lat, long) %>%
#   st_as_sf(coords = c('long', 'lat'), crs = 4326) %>%
#   st_transform(st_crs(region)) %>%
#   split(., c(1:10)) %>%
#   future_map(~st_join(.,region, join = st_nearest_feature), .progress = T)
# plan(sequential)
# 
# site.join <- rbind(site.join[[1]], site.join[[2]], site.join[[3]], site.join[[4]], site.join[[5]],
#                     site.join[[6]], site.join[[7]], site.join[[8]], site.join[[9]], site.join[[10]])
# 
# fieldMean <- wqp.lagos %>%
#   left_join(site.join) %>%
#   group_by(year, region) %>%
#   dplyr::summarize(mean = mean(median, na.rm = T),
#             sd = sd(median, na.rm =T),
#             count.obs = sum(count),
#             count.sites = n())
# 
# write_feather(fieldMean, 'out/RegionalsInSituMeans.feather')


## A little backwords but read in the bootstrapped predictions from 5_lake_analysis
fieldmatch.full <- read_feather('out/RegionalsInSituMeans.feather') %>% mutate(Measure = 'In.Situ') %>%
  select(year, region, mean, se = sd, Measure) %>% bind_rows(read_feather('out/TS_Preds/NLA2012_cntr_bootstrapped.feather') %>% mutate(Measure = 'Modelled'))


p1 <- fieldmatch.coin %>%
  ggplot(., aes(x = year, y = mean, color = Measure)) + 
  geom_line() + 
  scale_color_viridis_d(end = .6) +
  facet_wrap(~region, scales = 'free_y', ncol = 1) +
  labs(title = 'Coincident\nObservations') +
  theme_bw() +
  theme(legend.position = 'none',
        axis.title = element_blank())

p2 <- fieldmatch.full %>%
  ggplot(., aes(x = year, y = mean, color = Measure)) + 
  geom_line() + 
  scale_color_viridis_d(end = .6) +
  facet_wrap(~region, scales = 'free_y', ncol = 1) +
  labs(title = 'All\nObservations') +
  theme_bw() +
  theme(legend.position = 'right',
        axis.title = element_blank())

g <- grid.arrange(p1,p2, ncol = 2, widths = c(1,1.7), left = 'Mean Clarity (m)', bottom = 'Year')


ggsave('figures/CoinVFullObsShort.png', plot = g, width = 5.5, height = 7, units = 'in')

```

